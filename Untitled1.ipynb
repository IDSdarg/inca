{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.executable\n",
    "sys.path.append('C:/Users/Payal/Documents/GitHub/pattern/')\n",
    "import pattern\n",
    "import pandas as pd\n",
    "import inca\n",
    "from inca import Inca\n",
    "#from analysis_classification_class import classification\n",
    "import core.search_utils\n",
    "\n",
    "\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "#from sklearn.metrics import f1_score, precision_recall_fscore_support\n",
    "from sklearn.cross_validation import KFold\n",
    "from core.analysis_base_class import Analysis\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import string\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '42',\n",
       " '_index': 'my-index',\n",
       " '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
       " '_type': 'test-type',\n",
       " '_version': 34,\n",
       " 'created': False,\n",
       " 'result': 'updated'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from datetime import datetime\n",
    "es = Elasticsearch()\n",
    "es.index(index=\"my-index\", doc_type=\"test-type\", id=42, body={\"any\": \"data\", \"timestamp\": datetime.now()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Inca() # assumes elasticsearch is running\n",
    "generator_dm = client.database.doctype_generator('dailymail') # t\n",
    "myscraper_dm = inca.scrapers.dailymail_scraper.dailymail()   # make an instance of a nu.nl scraper\n",
    "myscraper_dm.run() # run the scraper. It takes the last articles from nu.nl and puts them into ELastic Search\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-28-406156c67069>, line 132)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-28-406156c67069>\"\u001b[1;36m, line \u001b[1;32m132\u001b[0m\n\u001b[1;33m    if tfidf =\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class classification(Analysis):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.vocab = None\n",
    "        self.train_predictions = None\n",
    "        self.X_test = None\n",
    "        self.y_test = None\n",
    "        self.predictions = None\n",
    "        self.accuracy = None\n",
    "        self.valid_docs = []\n",
    "        self.invalid_docs = []\n",
    "        self.vectorizer = None\n",
    "        self.tfidf_transformer = None\n",
    "\n",
    "        self.labels = []\n",
    "        \n",
    "        \n",
    "    def fit(self, documents, x_field, label_field, doctype=None, add_prediction=False, testsize = 0.2, mindf = 0.0, maxdf = 1.0, rand_shuffle = True, tfidf = True, vocabul = None):\n",
    "        \"\"\"\n",
    "        This method should train a Classifier model on the input documents.\\n\n",
    "        @param documents: the documents (stored in elasticsearch) to train on      \n",
    "        @type documents: iterable           \n",
    "        @param x_field: The nested field name that contains the text articles to be classified. Ideally nested within the '_source'\n",
    "                        field. For instance, to use nested field x2 as text document which is nested as doc['_source']['x1']['x2'], use\n",
    "                        '_source.x1.x2'\n",
    "                        (Makes a function call to core.basic_search.utilsdotkeys(dict, key_string) : allows the use of .-separated\n",
    "                        nested fields such as 'name.firstname' as dict[name][firstname])\n",
    "        @type x_field: str\n",
    "        @param label_field: The nested field name that contains the labels.Ideally would be nested within the '_source' field. For\n",
    "                            instance, to use nested field x2 as label which is nested as doc['_source']['x1']['x2'], use '_source.x1.x2'\n",
    "        @type label_field: str\n",
    "        @param doctype: the ElasticSearch doctype provided to the set of documents\n",
    "        @type doctype: str\n",
    "        @param add_prediction: this switch signals whether it is desired to obtain the class predictions for the train examples using the model trained on the train set itself.\\\n",
    "                               If given (add_prediction == True), then the in-sample, i.e., the train example class predictions as predicted by the model are outputted:\\n\n",
    "        @type add_prediction: Boolean\n",
    "        @param testsize: The proportion of labeled document examples to reserve as a test set. The default has been set as 0.2.\n",
    "        @type testsize: float\n",
    "        @param mindf: While creating the vocabulary (using a CountVectorizer from scikit), ignore all terms with a\n",
    "                      document frequency (that is, the proportion of train documents in which the term was found) strictly lower \n",
    "                      than the threshold specified by mindf. The default has been set to 0.0.\n",
    "        @type mindf: float\n",
    "        @param maxdf: While creating the vocabulary (using a CountVectorizer from scikit), ignore all terms with a document\n",
    "                      frequency (that is, the proportion of train documents in which the term was found) strictly higher than \n",
    "                      the threshold specified by maxdf. The default has been set to 1.0.\n",
    "        @type maxdf: float\n",
    "        @param rand_shuffle: If true, then the labeled document examples given as input, are randomly shuffled before splitting\n",
    "                             into a test and train set. If set to False, then no randomising is performed before the test-train \n",
    "                             split. The Default is set to True.\n",
    "        @type rand_shuffle: Boolean\n",
    "        @param tfidf: If true, then the Classifier model is based on the term-frequency-inverse-document-frequency instead of \n",
    "                      merely the term frequency. That is, it weights the frequency counts of words found in each document with\n",
    "                      the inverse document frequency (the number of documents that particuar word has occured.) The Default is \n",
    "                      set to True.\n",
    "        @type tfidf: Boolean\n",
    "        @param vocabul: This parameter accepts a list of words to be hard-fed as the vocabulary on basis of which the word \n",
    "                        frequency features are to be extracted from the input labeled documents. The default is set to None,\n",
    "                        in which case, all tokenised terms above the 'mindf', and below the 'maxdf' thresholds (defined above)\n",
    "                        encountered in the labeled documents are used to form the vocabulary.\n",
    "        @type vocabul: list, or None type object\n",
    "        \n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        counter = 0\n",
    "        invalidchars = set(string.punctuation)\n",
    "\n",
    "        for doc in documents:\n",
    "            counter+=1\n",
    "            if len(core.basic_utils.dotkeys(doc, x_field))>0:\n",
    "                self.valid_docs.append(doc['_id'])\n",
    "                self.labels.append(core.basic_utils.dotkeys(doc, label_field))             \n",
    "\n",
    "                if counter <5:\n",
    "                    text = core.basic_utils.dotkeys(doc, x_field).lower()\n",
    "                    if any(char in invalidchars for char in text):\n",
    "                        logger.info('Punctuation has not been removed. Proceeding without pre-processing.')\n",
    "\n",
    "\n",
    "            else: \n",
    "                self.invalid_docs.append(doc['_id'])\n",
    "       \n",
    "        documents = client.database.doctype_generator(doctype) \n",
    "\n",
    "        self.vectorizer = CountVectorizer(min_df = mindf, max_df = maxdf, vocabulary = vocabul) \n",
    "        counts = self.vectorizer.fit_transform((core.basic_utils.dotkeys(doc, x_field) for doc in documents if doc['_id'] not in self.invalid_docs), self.labels)\n",
    "\n",
    "        self.vocab = np.array(vectorizer.get_feature_names())\n",
    "           \n",
    "    \n",
    "        if tfidf:\n",
    "            self.tfidf_transformer = TfidfTransformer()        \n",
    "            tfidf_full_data = self.tfidf_transformer.fit_transform(counts, self.labels)\n",
    "            X_train, self.X_test, y_train, self.y_test = train_test_split(tfidf_full_data, self.labels, test_size=testsize, shuffle = rand_shuffle, random_state=42)\n",
    "        \n",
    "        else:\n",
    "            X_train, self.X_test, y_train, self.y_test = train_test_split(counts, self.labels, test_size = testsize, shuffle = rand_shuffle, random_state=42)\n",
    "        \n",
    "        self.model =  SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, max_iter=1000, random_state=42).fit(X_train, y_train)\n",
    "        print(type(X_train), '\\n', type(self.y_test))\n",
    "        #If predictions for training documents are desired\n",
    "        if add_prediction ==True:\n",
    "            self.train_predictions = self.model.predict(X_train)\n",
    "        else:\n",
    "            self.train_predictions = None\n",
    "                    \n",
    "        return (self.vocab, counts, self.labels)\n",
    "\n",
    "                                       \n",
    "    def predict(self, documents = None, x_field=None, doctype = None,  **kwargs):\n",
    "        \"\"\"\n",
    "        This method performs classification of new unseen documents.\\n\n",
    "        @param documents: the documents to classify.\n",
    "        @type documents: iterable, or a scipy sparse csr matrix of features (representing term frequencies or tfidf values).\n",
    "        @param x_field: The nested field name that contains the text articles to be classified. Ideally nested within the '_source'\n",
    "                        field. For instance, to use nested field x2 as text document which is nested as doc['_source']['x1']['x2'], use\n",
    "                        '_source.x1.x2'\n",
    "                        (Makes a function call to core.basic_search.utilsdotkeys(dict, key_string) : allows the use of .-separated\n",
    "                        nested fields such as 'name.firstname' as dict[name][firstname])\n",
    "        @type x_field: str\n",
    "        @param doctype: the ElasticSearch doctype provided to the set of documents\n",
    "        @type doctype: str        \n",
    "        \"\"\"\n",
    "        \n",
    "        if documents == None:\n",
    "            documents = self.X_test\n",
    "        else:\n",
    "            documents = self.vectorizer.transform(documents)\n",
    "            if tfidf = \n",
    "            \n",
    "        \n",
    "        print(type(self.X_test))\n",
    "        self.predictions = self.model.predict(documents)\n",
    "        print('no_of predictions : ',len(self.predictions))\n",
    "                                                                \n",
    "        return (self.predictions)\n",
    "                                                 \n",
    "                                                   \n",
    " \n",
    "    def quality(self, **kwargs):\n",
    "        \"\"\"\n",
    "        This method has the functionality to report on the quality of the underlying Classification (trained) model which was created as a random subset as a proportion of the input documents.\\n\n",
    "        The size of the test set is controlled through the parameter 'testsize' of the fit method of the Classification analyser object. The default proportion is 0.2, with random shuffle set as True.\\n\n",
    "        It calculates the categorization accuracy, precision, recall and f1-score on the test set of examples.\\n\n",
    "\n",
    "        \"\"\"\n",
    "        #make the test predictions as an attribute.\n",
    "\n",
    "        test_pred = self.model.predict(self.X_test)\n",
    "        self.test_accuracy = accuracy_score(self.y_test, test_pred)\n",
    "        self.test_precision = precision_score(self.y_test, test_pred, average = 'macro')\n",
    "        self.test_recall = recall_score(self.y_test, test_pred, average = 'macro')\n",
    "        self.test_f1score = f1_score(self.y_test, test_pred, average = 'macro')\n",
    "        print(\"accuracy on test set: \", self.test_accuracy , \"\\n Precision on test set: \" , self.test_precision , \"\\n Recall on test set: \"\n",
    "             , self.test_recall , \"\\n f1score : \" , self.test_f1score)\n",
    "        return (self.test_accuracy, self.test_precision, self.test_recall, self.test_f1score)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:core.search_utils:Filter has been replaced by query, still need to test whether edge cases might be unintentionally returned\n",
      "WARNING:core.search_utils:Filter has been replaced by query, still need to test whether edge cases might be unintentionally returned\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " new york (ap) - a new york federal judge who drew the ire of argentine government officials in a long-running case over argentina's debts has died. judge thomas p. griesa (grih-zay') was 87. manhattan federal court official edward friedland says griesa died sunday. the cause of the judge's death hasn't been disclosed. griesa presided for 15 years over lawsuits brought by u.s. hedge funds that bought heavily discounted argentine bonds after the country defaulted on debts in 2001. the hedge funds demanded full repayment of billions of dollars in bonds. argentina called the hedge funds \"vultures.\" griesa said the bonds must be paid in full. in 2014, argentina's then-president cristina fernandez called griesa \"senile\" and his finding \"silliness.\" after fernandez left office, the court case was settled. bondholders were paid more than $8 billion. 14349 14340\n",
      "<class 'scipy.sparse.csr.csr_matrix'> \n",
      " <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "client = Inca()\n",
    "generator_dm = client.database.doctype_generator('dailymail') \n",
    "class_instance = classification()\n",
    "#labels, invalid_docs, valid_docs = class_instance.fit(documents = generator_dm, doctype = 'dailymail' , x_field = '_source.text' , label_field = '_source.category', add_prediction=False)\n",
    "#doc_examples = inca.core.search_utils.doctype_examples('dailymail')  # # retrieve multiple example articles from elasticsearch#\n",
    "vocab, counts, labels= class_instance.fit( documents = generator_dm, x_field = '_source.text', label_field = '_source.category', doctype = 'dailymail' , add_prediction=False, rand_shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "no_of predictions :  2868\n"
     ]
    }
   ],
   "source": [
    "client = Inca()\n",
    "generator_dm = client.database.doctype_generator('dailymail')\n",
    "#class_instance = classification()\n",
    "#x_test = class_instance.X_test\n",
    "predi, acc =class_instance.predict(documents = class_instance.X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on test set:  0.820432357043 \n",
      " Precision on test set:  0.612329666771 \n",
      " Recall on test set:  0.394230618179 \n",
      " f1score :  0.446268483889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Payal\\Anaconda2\\envs\\inca1\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Payal\\Anaconda2\\envs\\inca1\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "client = Inca()\n",
    "generator_dm = client.database.doctype_generator('dailymail')\n",
    "testacc, testprec, testrecall, testf1 =class_instance.quality(documents = class_instance.X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class classification(Analysis):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.vocab = None\n",
    "        self.train_predictions = None\n",
    "        self.X_test = None\n",
    "        self.y_test = None\n",
    "        self.predictions = None\n",
    "        self.accuracy = None\n",
    "        self.valid_docs = []\n",
    "        self.invalid_docs = []\n",
    "        self.vectorizer = None\n",
    "\n",
    "        self.labels = []\n",
    "        \n",
    "        \n",
    "    def fit(self, documents, x_field, label_field, doctype=None, add_prediction=False, testsize = 0.2, mindf = 0.0, maxdf = 1.0, rand_shuffle = True, tfidf = True, vocabul = None):\n",
    "        \"\"\"\n",
    "        This method should train a Classifier model on the input documents.\\n\n",
    "        @param documents: the documents (stored in elasticsearch) to train on      \n",
    "        @type documents: iterable           \n",
    "        @param x_field: The nested field name that contains the text articles to be classified. Ideally nested within the '_source'\n",
    "                        field. For instance, to use nested field x2 as text document which is nested as doc['_source']['x1']['x2'], use\n",
    "                        '_source.x1.x2'\n",
    "                        (Makes a function call to core.basic_search.utilsdotkeys(dict, key_string) : allows the use of .-separated\n",
    "                        nested fields such as 'name.firstname' as dict[name][firstname])\n",
    "        @type x_field: str\n",
    "        @param label_field: The nested field name that contains the labels.Ideally would be nested within the '_source' field. For\n",
    "                            instance, to use nested field x2 as label which is nested as doc['_source']['x1']['x2'], use '_source.x1.x2'\n",
    "        @type label_field: str\n",
    "        @param doctype: the ElasticSearch doctype provided to the set of documents\n",
    "        @type doctype: str\n",
    "        @param add_prediction: this switch signals whether it is desired to obtain the class predictions for the train examples using the model trained on the train set itself.\\\n",
    "                               If given (add_prediction == True), then the in-sample, i.e., the train example class predictions as predicted by the model are outputted:\\n\n",
    "        @type add_prediction: Boolean\n",
    "        @param testsize: The proportion of labeled document examples to reserve as a test set. The default has been set as 0.2.\n",
    "        @type testsize: float\n",
    "        @param mindf: While creating the vocabulary (using a CountVectorizer from scikit), ignore all terms with a\n",
    "                      document frequency (that is, the proportion of train documents in which the term was found) strictly lower \n",
    "                      than the threshold specified by mindf. The default has been set to 0.0.\n",
    "        @type mindf: float\n",
    "        @param maxdf: While creating the vocabulary (using a CountVectorizer from scikit), ignore all terms with a document\n",
    "                      frequency (that is, the proportion of train documents in which the term was found) strictly higher than \n",
    "                      the threshold specified by maxdf. The default has been set to 1.0.\n",
    "        @type maxdf: float\n",
    "        @param rand_shuffle: If true, then the labeled document examples given as input, are randomly shuffled before splitting\n",
    "                             into a test and train set. If set to False, then no randomising is performed before the test-train \n",
    "                             split. The Default is set to True.\n",
    "        @type rand_shuffle: Boolean\n",
    "        @param tfidf: If true, then the Classifier model is based on the term-frequency-inverse-document-frequency instead of \n",
    "                      merely the term frequency. That is, it weights the frequency counts of words found in each document with\n",
    "                      the inverse document frequency (the number of documents that particuar word has occured.) The Default is \n",
    "                      set to True.\n",
    "        @type tfidf: Boolean\n",
    "        @param vocabul: This parameter accepts a list of words to be hard-fed as the vocabulary on basis of which the word \n",
    "                        frequency features are to be extracted from the input labeled documents. The default is set to None,\n",
    "                        in which case, all tokenised terms above the 'mindf', and below the 'maxdf' thresholds (defined above)\n",
    "                        encountered in the labeled documents are used to form the vocabulary.\n",
    "        @type vocabul: list, or None type object\n",
    "        \n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        counter = 0\n",
    "        invalidchars = set(string.punctuation)\n",
    "\n",
    "        for doc in documents:\n",
    "            counter+=1\n",
    "            if len(core.basic_utils.dotkeys(doc, x_field))>0:\n",
    "                self.valid_docs.append(doc['_id'])\n",
    "                self.labels.append(core.basic_utils.dotkeys(doc, label_field))             \n",
    "\n",
    "                if counter <5:\n",
    "                    text = core.basic_utils.dotkeys(doc, x_field).lower()\n",
    "                    if any(char in invalidchars for char in text):\n",
    "                        logger.info('Punctuation has not been removed. Proceeding without pre-processing.')\n",
    "\n",
    "\n",
    "            else: \n",
    "                self.invalid_docs.append(doc['_id'])\n",
    "       \n",
    "        documents = client.database.doctype_generator(doctype) \n",
    "\n",
    "        self.vectorizer = CountVectorizer(min_df = mindf, max_df = maxdf, vocabulary = vocabul) \n",
    "        counts = self.vectorizer.fit_transform((core.basic_utils.dotkeys(doc, x_field) for doc in documents if doc['_id'] not in self.invalid_docs), self.labels)\n",
    "\n",
    "        self.vocab = np.array(self.vectorizer.get_feature_names())\n",
    "           \n",
    "    \n",
    "        if tfidf:\n",
    "            self.vectorizer = TfidfTransformer()        \n",
    "            tfidf_full_data = self.vectorizer.fit_transform(counts, self.labels)\n",
    "            X_train, self.X_test, y_train, self.y_test = train_test_split(tfidf_full_data, self.labels, test_size=testsize, shuffle = rand_shuffle, random_state=42)\n",
    "        \n",
    "        else:\n",
    "            X_train, self.X_test, y_train, self.y_test = train_test_split(counts, self.labels, test_size = testsize, shuffle = rand_shuffle, random_state=42)\n",
    "        \n",
    "        self.model =  SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, max_iter=1000, random_state=42).fit(X_train, y_train)\n",
    "        print(type(X_train), '\\n', type(self.y_test))\n",
    "        #If predictions for training documents are desired\n",
    "        if add_prediction ==True:\n",
    "            self.train_predictions = self.model.predict(X_train)\n",
    "        else:\n",
    "            self.train_predictions = None\n",
    "                    \n",
    "        return (self.vocab, counts, self.labels)\n",
    "\n",
    "                                       \n",
    "    def predict(self, documents = None, x_field=None, doctype = None,  **kwargs):\n",
    "        \"\"\"\n",
    "        This method performs classification of new unseen documents.\\n\n",
    "        @param documents: the documents to classify.\n",
    "        @type documents: iterable, or a scipy sparse csr matrix of features (representing term frequencies or tfidf values).\n",
    "        @param x_field: The nested field name that contains the text articles to be classified. Ideally nested within the '_source'\n",
    "                        field. For instance, to use nested field x2 as text document which is nested as doc['_source']['x1']['x2'], use\n",
    "                        '_source.x1.x2'\n",
    "                        (Makes a function call to core.basic_search.utilsdotkeys(dict, key_string) : allows the use of .-separated\n",
    "                        nested fields such as 'name.firstname' as dict[name][firstname])\n",
    "        @type x_field: str\n",
    "        @param doctype: the ElasticSearch doctype provided to the set of documents\n",
    "        @type doctype: str        \n",
    "        \"\"\"\n",
    "        \n",
    "        if documents == None:\n",
    "            documents = self.X_test\n",
    "        else:\n",
    "            documents = self.vectorizer.transform(documents)\n",
    "          \n",
    "        \n",
    "        print(type(self.X_test))\n",
    "        self.predictions = self.model.predict(documents)\n",
    "        print('no_of predictions : ',len(self.predictions))\n",
    "                                                                \n",
    "        return (self.predictions)\n",
    "                                                 \n",
    "                                                   \n",
    " \n",
    "    def quality(self, **kwargs):\n",
    "        \"\"\"\n",
    "        This method has the functionality to report on the quality of the underlying Classification (trained) model which was created as a random subset as a proportion of the input documents.\\n\n",
    "        The size of the test set is controlled through the parameter 'testsize' of the fit method of the Classification analyser object. The default proportion is 0.2, with random shuffle set as True.\\n\n",
    "        It calculates the categorization accuracy, precision, recall and f1-score on the test set of examples.\\n\n",
    "\n",
    "        \"\"\"\n",
    "        #make the test predictions as an attribute.\n",
    "\n",
    "        test_pred = self.model.predict(self.X_test)\n",
    "        self.test_accuracy = accuracy_score(self.y_test, test_pred)\n",
    "        self.test_precision = precision_score(self.y_test, test_pred, average = 'macro')\n",
    "        self.test_recall = recall_score(self.y_test, test_pred, average = 'macro')\n",
    "        self.test_f1score = f1_score(self.y_test, test_pred, average = 'macro')\n",
    "        print(\"accuracy on test set: \", self.test_accuracy , \"\\n Precision on test set: \" , self.test_precision , \"\\n Recall on test set: \"\n",
    "             , self.test_recall , \"\\n f1score : \" , self.test_f1score)\n",
    "        return (self.test_accuracy, self.test_precision, self.test_recall, self.test_f1score)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:core.search_utils:Filter has been replaced by query, still need to test whether edge cases might be unintentionally returned\n",
      "WARNING:core.search_utils:Filter has been replaced by query, still need to test whether edge cases might be unintentionally returned\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'> \n",
      " <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "client = Inca()\n",
    "generator_dm = client.database.doctype_generator('dailymail')\n",
    "instance2 = classification()\n",
    "vocab, counts, labels= instance2.fit( documents = generator_dm, x_field = '_source.text', label_field = '_source.category', doctype = 'dailymail' , mindf = 0.2, maxdf = 0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on test set:  0.820432357043 \n",
      " Precision on test set:  0.612329666771 \n",
      " Recall on test set:  0.394230618179 \n",
      " f1score :  0.446268483889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Payal\\Anaconda2\\envs\\inca1\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Payal\\Anaconda2\\envs\\inca1\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "client = Inca()\n",
    "generator_dm = client.database.doctype_generator('dailymail')\n",
    "testacc, testprec, testrecall, testf1 =class_instance.quality(documents = class_instance.X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (inca1)",
   "language": "python",
   "name": "inca1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
