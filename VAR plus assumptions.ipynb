{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector AutoRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class inherets from Base_Analysis_Class and provides some simple functionality for: \n",
    "    1. Checking stationarity of (multiple) time-series\n",
    "    \n",
    "    2. Plotting timeline, lag-plot, autocorrelation plot (you need to be on ipython environment)\n",
    "    \n",
    "    3. Creating and fitting VAR model based on the dataframe (index=time variable) provided from the 'timeline' class. Here, you can speicfy:\n",
    "        - N-lags /ByDefault statsmodels chooses the most apporporate lag for you based on Ljung-Box             Q-score. \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blueprint of the class VAR \n",
    "#requirements: \n",
    "from core.analysis_base_class import Analysis\n",
    "from statsmodels.tsa.api import VAR as var \n",
    "from statsmodels.tsa.stattools import adfuller,kpss\n",
    "from matplotlib import pyplot\n",
    "from pandas.plotting import lag_plot\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "\n",
    "class VAR(Analysis):\n",
    "    \"\"\" VAR works with dataframes (or a sereis) \"\"\"\n",
    "    \n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "        self.temp = 0.0   ##\n",
    "          \n",
    "\n",
    "    def test_assumptions(self,level):\n",
    "        \"\"\" \n",
    "        Gives you output as list with assumptions stated as satisfied/not satisfied. If some important \n",
    "        assumptions are not satisfied gives you warning that you have to transform your data. \n",
    "        @df - dataframe with columns representing queries (eg count number of documents \n",
    "               whcich mention a word or phrase)\n",
    "        @level -  this is the level you are testing your asusmptions on (either 1,5 or 10 %)\n",
    "        \"\"\"\n",
    "        self.level =  level\n",
    "        \n",
    "        def _adf_test():\n",
    "            \"\"\" \n",
    "            H_0: the observed time series is stationary \n",
    "            Returns: dataframe of summary of the test \n",
    "            \"\"\"\n",
    "            summary_adf = pd.DataFrame(columns=['ADF_Stat','p-value','Critical_val_1%','Critical_val_5%','Critical_val_10%'])\n",
    "            for name in self.df.columns:\n",
    "                series = self.df[name]\n",
    "                result = adfuller(series)\n",
    "                dic = {'ADF_Stat':result[0],'p-value':result[1],'Critical_val_1%':result[4]['1%'],'Critical_val_5%':result[4]['5%'],\n",
    "                       'Critical_val_10%':result[4]['10%']}\n",
    "                summary_adf = summary_adf.append(dic,ignore_index=True)\n",
    "            summary_adf.set_index(df.columns,inplace=True)  \n",
    "\n",
    "            return summary_adf \n",
    "    \n",
    "        def _kpss_test():\n",
    "            \"\"\" \n",
    "            H_0: there is a unit root in time series, hence stochastic trend with drift, hence non-stationary\n",
    "            Returns: dataframe of summary of the test\n",
    "            \"\"\"\n",
    "            summary_kpss = pd.DataFrame(columns=['KPSS_Stat','p-value','Critical_val_1%','Critical_val_5%','Critical_val_10%'])\n",
    "            for name in self.df.columns:\n",
    "                series = self.df[name]\n",
    "                result = kpss(series)\n",
    "                dic = {'KPSS_Stat':result[0],'p-value':result[1],'Critical_val_1%':result[3]['1%'],'Critical_val_5%':result[3]['5%'],\n",
    "                       'Critical_val_10%':result[3]['10%']}\n",
    "                summary_kpss = summary_kpss.append(dic,ignore_index=True)\n",
    "            summary_kpss.set_index(df.columns,inplace=True)  \n",
    "\n",
    "            return summary_kpss\n",
    "        \n",
    "        def _stationarity_check(explicit=True):\n",
    "            \"\"\" \n",
    "            For each time series return the result of the check - return in created dataframe\n",
    "            \"\"\"\n",
    "            lvl = float(self.level[:-1])/100 \n",
    "            self.summary_adf = _adf_test()\n",
    "            self.summary_kpss = _kpss_test()\n",
    "            \n",
    "            if explicit:\n",
    "                for i in self.df.columns:\n",
    "                    adf_flag = lvl > self.summary_adf.loc[i,'p-value']\n",
    "                    kpss_flag = lvl < self.summary_kpss.loc[i,'p-value']\n",
    "                    print(\"For {} stationarity is satisfied: ADF - {} | KPSS - {} \".format(i,adf_flag, kpss_flag)) # PRINT  (!)\n",
    "                    \n",
    "            return  ##\n",
    "        \n",
    "        call_stationarity = _stationarity_check(explicit=True)\n",
    "        return ##\n",
    "\n",
    "    def fit(self,nlags=None):\n",
    "        \"\"\"\n",
    "        This method creates a Vector AutoRegressive model to timeline dataframe\n",
    "        @df - dataframe with columns representing queries (eg count number of documents \n",
    "               whcich mention a word or phrase) \n",
    "        @nlags -  number of lags to consider \n",
    "        \"\"\"\n",
    "        self.model = var(self.df)                           # creating VAR model , could go to __init__\n",
    "        self.result = self.model.fit(nlags)   \n",
    "        self.order = self.model.select_order(verbose=True)\n",
    "        print(self.order['bic'])   ##selects lag based on infomation criteria\n",
    "        return ###\n",
    "\n",
    "    def predict(self,d = 5):\n",
    "        \"\"\"\n",
    "        Makes forecasts based on the parameters of fitted model \n",
    "        @ d - how many steps into the future you want to forecast \n",
    "        \"\"\"\n",
    "        prediction_array= self.result.forecast(self.df.values,d)\n",
    "        \n",
    "        predictions = pd.DataFrame(prediction_array, columns= self.df.columns)\n",
    "        print(predictions)     ###\n",
    "        return ## \n",
    "\n",
    "\n",
    "    def interpretation(self, **kwargs):\n",
    "        \"\"\"\n",
    "        This method should have the functionality to interpret the status of the model after being trained and also document the various design choices\\\n",
    "        (i.e. parameters settings, assumptions, model selection, test method, dataset used). For example it can return a report-like looking formatted string.\\n\n",
    "        Please consider the following as possible model state interpretation:\\n\n",
    "           * For classification tasks depending on the underlying model: coeficient/feature weights, feature selection (random forest)\\n\n",
    "           * For clustering tasks: clusterings members/structure, distributions\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def diagnostics(self):\n",
    "        \"\"\"\n",
    "        This method should have the functionality to report on the quality of the underlying (trained) model used for \n",
    "        the analysis (on a dataset)\n",
    "           \n",
    "        Common diagnostics for VAR: check noramlity of residuals\n",
    "        \"\"\"\n",
    "        residuals = self.result.resid\n",
    "        print(residuals)\n",
    "        return ##\n",
    "\n",
    "    def plot(self, plot_type=None, lag = 1):\n",
    "        \"\"\"\n",
    "        To be able to see the results this method requires an ipython environment run\n",
    "        \"\"\"\n",
    "        def lag_scatter():\n",
    "            for name in self.df.columns:\n",
    "                series = self.df[name]\n",
    "                print(\"Lag plot where y is {}\".format(name))\n",
    "                lag_plot(series,lag)\n",
    "                pyplot.show()    \n",
    "\n",
    "            return ##\n",
    "        \n",
    "        def line_plot():\n",
    "            for name in self.df.columns:\n",
    "                series = self.df[name]\n",
    "                series.plot(legend=True)\n",
    "            pyplot.show()\n",
    "            return ##\n",
    "    \n",
    "        def autocorrelation_plot():\n",
    "            for name in self.df.columns:\n",
    "                series = self.df[name]\n",
    "                print(\"Autocorelation plot for {}\".format(name))\n",
    "                plot_acf(series, lags=lag)\n",
    "                pyplot.show()\n",
    "            \n",
    "        if plot_type == None:\n",
    "            lag_scatter() \n",
    "            line_plot()\n",
    "            autocorrelation_plot()\n",
    "        if (plot_type == ('line')):\n",
    "            line_plot()\n",
    "        if (plot_type == ('lag')):\n",
    "            lag_scatter()\n",
    "        if (plot_type == ('autocorrelation')):\n",
    "            autocorrelation_plot()\n",
    "        \n",
    "        return ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<statsmodels.tsa.vector_ar.var_model.VARResultsWrapper at 0x290d7d77b00>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = var(df)\n",
    "res = m2.fit(2)\n",
    "m2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate two arbitrary sample to work with, put them in df, add time trend\n",
    "sample1 = np.random.gamma(4,3,50)\n",
    "sample2 = np.random.binomial(10,0.7,size=50)\n",
    "\n",
    "# create a pandas dataframe with counts of mentions of a particular word (two arrays)\n",
    "df = pd.DataFrame({'x':sample1, 'y':sample2})\n",
    "df['t'] = df.index\n",
    "df['x'] = df.x.astype('int')\n",
    "df = df.drop(['t'],axis=1)\n",
    "\n",
    "#make index a date object\n",
    "import datetime\n",
    "base = datetime.datetime.today()\n",
    "date_list = [base - datetime.timedelta(days=x) for x in range(0, 50)]\n",
    "\n",
    "df.index = date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For x stationarity is satisfied: ADF - True | KPSS - True \n",
      "For y stationarity is satisfied: ADF - True | KPSS - True \n",
      "                 VAR Order Selection                  \n",
      "======================================================\n",
      "            aic          bic          fpe         hqic\n",
      "------------------------------------------------------\n",
      "0         4.461       4.545*       86.55*       4.491*\n",
      "1         4.533        4.786        93.09        4.625\n",
      "2         4.597        5.019        99.47        4.750\n",
      "3         4.740        5.331        115.2        4.953\n",
      "4         4.735        5.495        115.7        5.010\n",
      "5         4.897        5.826        137.8        5.233\n",
      "6         4.933        6.031        145.8        5.330\n",
      "7         4.910        6.177        146.6        5.368\n",
      "8         4.791        6.226        135.0        5.310\n",
      "9         4.718        6.323        132.2        5.298\n",
      "10       4.410*        6.184        103.9        5.051\n",
      "======================================================\n",
      "* Minimum\n",
      "\n",
      "0\n",
      "                                    x         y\n",
      "2017-11-20 23:07:43.261708  -4.702464  0.767851\n",
      "2017-11-19 23:07:43.261708  -1.727410 -1.147549\n",
      "2017-11-18 23:07:43.261708  -3.465208  1.804846\n",
      "2017-11-17 23:07:43.261708  -2.883009  1.862224\n",
      "2017-11-16 23:07:43.261708  24.133322  0.871577\n",
      "2017-11-15 23:07:43.261708   6.052113 -0.273821\n",
      "2017-11-14 23:07:43.261708  -0.669801 -2.213442\n",
      "2017-11-13 23:07:43.261708  11.657728  2.776367\n",
      "2017-11-12 23:07:43.261708   4.847071 -0.193478\n",
      "2017-11-11 23:07:43.261708   9.354696 -0.199412\n",
      "2017-11-10 23:07:43.261708  -4.702464 -3.232149\n",
      "2017-11-09 23:07:43.261708  -1.170341  0.775948\n",
      "2017-11-08 23:07:43.261708   2.223595 -1.175609\n",
      "2017-11-07 23:07:43.261708  -7.497871 -0.213861\n",
      "2017-11-06 23:07:43.261708  -1.571812  0.842679\n",
      "2017-11-05 23:07:43.261708  -5.751908 -0.161579\n",
      "2017-11-04 23:07:43.261708   4.428188  0.842679\n",
      "2017-11-03 23:07:43.261708   6.199097  2.810361\n",
      "2017-11-02 23:07:43.261708  -6.087603 -0.156064\n",
      "2017-11-01 23:07:43.261708  -2.555480  1.852032\n",
      "2017-10-31 23:07:43.261708  -4.883009 -1.137776\n",
      "2017-10-30 23:07:43.261708  -3.432544 -0.176447\n",
      "2017-10-29 23:07:43.261708  -5.604475 -2.176028\n",
      "2017-10-28 23:07:43.261708  -4.301443 -3.200250\n",
      "2017-10-27 23:07:43.261708  -4.186673 -0.233406\n",
      "2017-10-26 23:07:43.261708  -2.612641 -1.180705\n",
      "2017-10-25 23:07:43.261708   8.534792 -2.195154\n",
      "2017-10-24 23:07:43.261708   2.576070  0.729599\n",
      "2017-10-23 23:07:43.261708  -3.800903 -1.189639\n",
      "2017-10-22 23:07:43.261708   0.551124 -0.185800\n",
      "2017-10-21 23:07:43.261708  -4.637138  0.805265\n",
      "2017-10-20 23:07:43.261708  -1.727410 -2.147549\n",
      "2017-10-19 23:07:43.261708   7.674060 -0.214280\n",
      "2017-10-18 23:07:43.261708  -6.702464  0.767851\n",
      "2017-10-17 23:07:43.261708  -7.711079  2.861805\n",
      "2017-10-16 23:07:43.261708   1.026718 -1.090590\n",
      "2017-10-15 23:07:43.261708  12.526627 -1.199831\n",
      "2017-10-14 23:07:43.261708   3.404140  2.730018\n",
      "2017-10-13 23:07:43.261708   2.920563  0.848612\n",
      "2017-10-12 23:07:43.261708  -6.768239  2.829068\n",
      "2017-10-11 23:07:43.261708   3.018552  0.904733\n",
      "2017-10-10 23:07:43.261708  -8.768239 -1.170932\n",
      "2017-10-09 23:07:43.261708   0.591953  0.837583\n",
      "2017-10-08 23:07:43.261708  -7.776405 -2.175609\n",
      "2017-10-07 23:07:43.261708  -1.276945 -0.186219\n",
      "2017-10-06 23:07:43.261708  -7.628972 -0.190058\n",
      "2017-10-05 23:07:43.261708   5.436354  0.847356\n",
      "2017-10-04 23:07:43.261708  -1.809068  0.805684\n",
      "2017-10-03 23:07:43.261708   9.256258 -1.156902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda2\\envs\\inca362\\lib\\site-packages\\statsmodels\\tsa\\stattools.py:1260: InterpolationWarning: p-value is greater than the indicated p-value\n",
      "  warn(\"p-value is greater than the indicated p-value\", InterpolationWarning)\n"
     ]
    }
   ],
   "source": [
    "m1 = VAR(df)\n",
    "m1.test_assumptions('1%')\n",
    "m1.fit()\n",
    "#m1.predict()\n",
    "#m1.plot(plot_type = 'autocorrelation' ,lag = 2)\n",
    "m1.diagnostics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-15 12:57:19.273678</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-14 12:57:19.273678</th>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13 12:57:19.273678</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12 12:57:19.273678</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 12:57:19.273678</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-10 12:57:19.273678</th>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-09 12:57:19.273678</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-08 12:57:19.273678</th>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-07 12:57:19.273678</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-06 12:57:19.273678</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-05 12:57:19.273678</th>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-04 12:57:19.273678</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-03 12:57:19.273678</th>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-02 12:57:19.273678</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01 12:57:19.273678</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-31 12:57:19.273678</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-30 12:57:19.273678</th>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-29 12:57:19.273678</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-28 12:57:19.273678</th>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-27 12:57:19.273678</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-26 12:57:19.273678</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-25 12:57:19.273678</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-24 12:57:19.273678</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-23 12:57:19.273678</th>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-22 12:57:19.273678</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-21 12:57:19.273678</th>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-20 12:57:19.273678</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-19 12:57:19.273678</th>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-18 12:57:19.273678</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-17 12:57:19.273678</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-16 12:57:19.273678</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-15 12:57:19.273678</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-14 12:57:19.273678</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-13 12:57:19.273678</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-12 12:57:19.273678</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-11 12:57:19.273678</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-10 12:57:19.273678</th>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-09 12:57:19.273678</th>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-08 12:57:19.273678</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-07 12:57:19.273678</th>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-06 12:57:19.273678</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-05 12:57:19.273678</th>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-04 12:57:19.273678</th>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-03 12:57:19.273678</th>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 12:57:19.273678</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-01 12:57:19.273678</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-30 12:57:19.273678</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-29 12:57:19.273678</th>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-28 12:57:19.273678</th>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-27 12:57:19.273678</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             x   y\n",
       "2017-11-15 12:57:19.273678   3   9\n",
       "2017-11-14 12:57:19.273678  13   6\n",
       "2017-11-13 12:57:19.273678   8   9\n",
       "2017-11-12 12:57:19.273678   8  10\n",
       "2017-11-11 12:57:19.273678  11   7\n",
       "2017-11-10 12:57:19.273678  11   6\n",
       "2017-11-09 12:57:19.273678   6   7\n",
       "2017-11-08 12:57:19.273678  20   7\n",
       "2017-11-07 12:57:19.273678  10   8\n",
       "2017-11-06 12:57:19.273678   7  10\n",
       "2017-11-05 12:57:19.273678  18   6\n",
       "2017-11-04 12:57:19.273678   3   8\n",
       "2017-11-03 12:57:19.273678  20   8\n",
       "2017-11-02 12:57:19.273678  18   7\n",
       "2017-11-01 12:57:19.273678   6   7\n",
       "2017-10-31 12:57:19.273678  10   6\n",
       "2017-10-30 12:57:19.273678  13   8\n",
       "2017-10-29 12:57:19.273678   5   6\n",
       "2017-10-28 12:57:19.273678  14   7\n",
       "2017-10-27 12:57:19.273678   6   6\n",
       "2017-10-26 12:57:19.273678   6   9\n",
       "2017-10-25 12:57:19.273678   2   8\n",
       "2017-10-24 12:57:19.273678   8   8\n",
       "2017-10-23 12:57:19.273678  33   7\n",
       "2017-10-22 12:57:19.273678   7   5\n",
       "2017-10-21 12:57:19.273678  12   8\n",
       "2017-10-20 12:57:19.273678   7   6\n",
       "2017-10-19 12:57:19.273678  21   5\n",
       "2017-10-18 12:57:19.273678   7   7\n",
       "2017-10-17 12:57:19.273678   5   8\n",
       "2017-10-16 12:57:19.273678   5   6\n",
       "2017-10-15 12:57:19.273678   8   9\n",
       "2017-10-14 12:57:19.273678   9   8\n",
       "2017-10-13 12:57:19.273678   6   9\n",
       "2017-10-12 12:57:19.273678   1   7\n",
       "2017-10-11 12:57:19.273678  11   7\n",
       "2017-10-10 12:57:19.273678  16   7\n",
       "2017-10-09 12:57:19.273678  13   6\n",
       "2017-10-08 12:57:19.273678   9   7\n",
       "2017-10-07 12:57:19.273678  19   5\n",
       "2017-10-06 12:57:19.273678  10   8\n",
       "2017-10-05 12:57:19.273678  14   8\n",
       "2017-10-04 12:57:19.273678  14   8\n",
       "2017-10-03 12:57:19.273678  13   9\n",
       "2017-10-02 12:57:19.273678  11  10\n",
       "2017-10-01 12:57:19.273678   5  10\n",
       "2017-09-30 12:57:19.273678   8   5\n",
       "2017-09-29 12:57:19.273678  12   9\n",
       "2017-09-28 12:57:19.273678  16   9\n",
       "2017-09-27 12:57:19.273678   9   7"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inca362",
   "language": "python",
   "name": "inca362"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
