{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda2\\envs\\inca362\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "# Blueprint of the class VAR \n",
    "#requirements: \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging \n",
    "from core.analysis_base_class import Analysis\n",
    "from analysis import timeline_analysis as ta\n",
    "from statsmodels.tsa.api import VAR as var \n",
    "from statsmodels.tsa.stattools import adfuller,kpss\n",
    "from statsmodels.tsa.tsatools import detrend\n",
    "from matplotlib import pyplot\n",
    "from pandas.plotting import lag_plot\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class VAR(Analysis):\n",
    "    \"\"\" When creating var model we first generate a timeline in the form of pandas df. Then feed it to VAR method in statsmodels.\n",
    "        We can save the names of the variables(queries) this way so no need of mapping (var to name) on the later stages,\n",
    "        awesome plotting functionality and just comfortable to work with for everyone. \n",
    "    \"\"\"\n",
    "     \n",
    "    def __init__(self):  \n",
    "        \"\"\"creates variables: \n",
    "            @self.flag_stationarity = boolean of whether assumptions checks for VAR were run ## delete?!\n",
    "        \"\"\"\n",
    "        self.flag_stationarity = False\n",
    "        \n",
    "    \n",
    "    def fit(self,queries,timefield,granularity,querytype=\"count\",nlags=None, **kwargs):\n",
    "        \"\"\" @queries  = what do you want to query from ES ? eg queries = ['Trump','Hillary']\n",
    "            @timefield = what field do you want to use to get the dates/timeline from ? 'META.ADDED'\n",
    "            @granularity = 'day'/'week'/'month' etc \n",
    "            @nlags -  number of lags to consider, if none - rely on statsmodels to choose lag for you \n",
    "            \n",
    "            Possible kwargs to be added later:\n",
    "                @level = confidence level for all your test (!) , default = 5%\n",
    "                @from_time - \n",
    "                @to_time -\n",
    "                @do_assump_check = True/False    ##\n",
    "                @do_transfomations = True/False   ##\n",
    "                @max_order_diff = maximum order of differencing, default = 2  \n",
    "                @max_order_detrend = maximum order of detredning, default = 2\n",
    "                @stationarity_kpss = True/False, False is default, hence you do ADF test\n",
    "        \"\"\"\n",
    "        self.max_order_diff = kwargs.get('max_order_diff',2)\n",
    "        self.max_order_detrend = kwargs.get('max_order_detrend',2)\n",
    "        self.stationarity_kpss = kwargs.get('stationarity_kpss',False)\n",
    "        self.level = kwargs.get('level','5%')\n",
    "        self.from_time = kwargs.get('from_time',None)\n",
    "        self.to_time = kwargs.get('to_time',None)\n",
    "        \n",
    "        timeline = ta.timeline_generator()\n",
    "        df_raw = timeline.analyse(queries=queries,timefield = timefield, granularity = granularity,\n",
    "                                 from_time=self.from_time,to_time=self.to_time)\n",
    "        df_raw.index = df_raw.timestamp\n",
    "        df_raw = df_raw.drop('timestamp',axis=1) \n",
    "        self.df_raw = df_raw\n",
    "        \n",
    "        \n",
    "\n",
    "        # Do the stationarity modifications\n",
    "        logger.warning(\"Before fitting, I automatically check stationarity assumption\") \n",
    "        check_1 = self.test_assumptions(df_raw)    \n",
    "        \n",
    "        # Fit the VAR model \n",
    "        if self.flag_stationarity == True: \n",
    "            logger.warning(\"You are good to go\")\n",
    "        else: \n",
    "            logger.warning(\"Be warned: some time series are still non-stationary\")\n",
    "        self.model = var(self.df)\n",
    "        self.result = self.model.fit(nlags) \n",
    "        \n",
    "        #Lets do diagnostics: \n",
    "        check_2 = self.diagnostics()\n",
    "        \n",
    "        return # what do we return? \n",
    "\n",
    "    def test_assumptions(self, df, level='5%', **kwargs):\n",
    "        \"\"\" This method checks if df_raw needs to be made stationary; if stationary this becomes df \n",
    "            which you then use for the fit method; if your raw df is not stationary then we do transfomations \n",
    "            such as differencing or detrending. \n",
    "                        \n",
    "        @df - 'active' df which we might want to modify\n",
    "        @level -  this is the level you are testing your asusmptions on. \n",
    "                  NOTE: when test_assump called from fit method level is set by kwarg or default is 5%\n",
    "        @test_type - either adf or kpss\n",
    "        \"\"\"\n",
    "        def _adf_test(df):\n",
    "            \"\"\" \n",
    "            H_0: the observed time series is stationary \n",
    "            Returns: dataframe of summary of the test \n",
    "            \"\"\"\n",
    "            summary_adf = pd.DataFrame(columns=['ADF_Stat','p-value','Critical_val_1%','Critical_val_5%','Critical_val_10%'])\n",
    "            for name in df.columns:\n",
    "                series = df[name]\n",
    "                result = adfuller(series)\n",
    "                dic = {'ADF_Stat':result[0],'p-value':result[1],'Critical_val_1%':result[4]['1%'],'Critical_val_5%':result[4]['5%'],\n",
    "                       'Critical_val_10%':result[4]['10%']}\n",
    "                summary_adf = summary_adf.append(dic,ignore_index=True)\n",
    "            summary_adf.set_index(df.columns,inplace=True)  \n",
    "\n",
    "            return summary_adf \n",
    "        \n",
    "        def _kpss_test(df):\n",
    "            \"\"\" \n",
    "            H_0: there is a unit root in time series, hence stochastic trend with drift, hence non-stationary\n",
    "            Returns: dataframe of summary of the test\n",
    "            \"\"\"\n",
    "            summary_kpss = pd.DataFrame(columns=['KPSS_Stat','p-value','Critical_val_1%','Critical_val_5%','Critical_val_10%'])\n",
    "            for name in df.columns:\n",
    "                series = df[name]\n",
    "                result = kpss(series)\n",
    "                dic = {'KPSS_Stat':result[0],'p-value':result[1],'Critical_val_1%':result[3]['1%'],'Critical_val_5%':result[3]['5%'],\n",
    "                       'Critical_val_10%':result[3]['10%']}\n",
    "                summary_kpss = summary_kpss.append(dic,ignore_index=True)\n",
    "            summary_kpss.set_index(df.columns,inplace=True)  \n",
    "\n",
    "            return summary_kpss\n",
    "        \n",
    "        def _stationary(df):\n",
    "            \"\"\" \n",
    "            For each time series return the result of the check - return in created dataframe ?\n",
    "            Uses by default adf_ test, but if you want kpss test you have to give an argument\n",
    "            \"\"\"\n",
    "            lvl = float(self.level[:-1])/100 \n",
    "            stat_flag = True                    # if test failed, we assume we need to take action \n",
    "            if self.stationarity_kpss == False:\n",
    "                self.summary_adf = _adf_test(df)\n",
    "                for i in df.columns:\n",
    "                    adf_flag = lvl > self.summary_adf.loc[i,'p-value']\n",
    "                    if (adf_flag == False):\n",
    "                        stat_flag = False \n",
    "                    print(\"For {} stationarity is satisfied: ADF - {}\".format(i,adf_flag)) ## PRINT (!)\n",
    "            else:\n",
    "                self.summary_kpss = _kpss_test(df)\n",
    "                for i in df.columns:\n",
    "                    kpss_flag = lvl < self.summary_kpss.loc[i,'p-value']\n",
    "                    if (kpss_flag == False):\n",
    "                        stat_flag = False \n",
    "                    print(\"For {} stationarity is satisfied: KPSS - {}\".format(i,kpss_flag))  ## \n",
    "            \n",
    "            return stat_flag \n",
    "        \n",
    "        def differencing(df, order=1):\n",
    "            \"\"\" If there is no stationarity: try differencing\n",
    "            \"\"\"  \n",
    "            helped = False   ## boolean check if differencing helped \n",
    "            def _perform_differencing():\n",
    "            # Perform differencing:  \n",
    "                df_diff = pd.DataFrame(columns=df.columns)\n",
    "                for name in df.columns:\n",
    "                    series = df[name]\n",
    "                    series = series.diff(order)\n",
    "                    df_diff[name] = series.dropna(axis=0)\n",
    "                \n",
    "                return _stationary(df_diff), df_diff   \n",
    "            \n",
    "            stat_check_after_diff, df_diff = _perform_differencing()\n",
    "            print('Differencing helped?')   ##            \n",
    "            print(stat_check_after_diff)   ##\n",
    "            \n",
    "            ## if differencing helped update self.df => self.df = df_diff \n",
    "            if stat_check_after_diff == True: \n",
    "                self.df = df_diff       ## CREATING FINAL DF for the first time if differncing helped\n",
    "                helped = True   \n",
    "                \n",
    "            return helped\n",
    "        \n",
    "        def detrending(df, order=1):\n",
    "            \"\"\" If there is no stationarity: differencing did not help - detrend\n",
    "               (!) does not work nicely with time series where there is a lot of zeros and high volatility :(\n",
    "            \"\"\"     \n",
    "            helped = False  ## boolean check if detrending helped\n",
    "            def _perform_detrending():\n",
    "            # Perform detrending:  \n",
    "                df_res = pd.DataFrame(columns=df.columns)\n",
    "                for name in df.columns:\n",
    "                    series = df[name]\n",
    "                    res = detrend(series,order)\n",
    "                    df_res[name] = series.dropna(axis=0)\n",
    "                \n",
    "                return _stationary(df_res), df_res  \n",
    "            \n",
    "            stat_check_after_detrend, df_detrended = _perform_detrending()\n",
    "            print('Detrending helped?')       ##            \n",
    "            print(stat_check_after_detrend)   ##\n",
    "            \n",
    "            ## if detrending helped update self.df => self.df = df_diff \n",
    "            if stat_check_after_detrend == True: \n",
    "                self.df = df_detrended             # CREATING FINAL DF for the first time if detrending helped\n",
    "                helped = True   \n",
    "            \n",
    "            return helped\n",
    "        \n",
    "        # Run the check on df_raw and do transformations if necessery \n",
    "        self.flag_stationarity = _stationary(df)\n",
    "        \n",
    "        #self.flag_stationarity  = False                       ## Delete, just for testing ##\n",
    "        \n",
    "        if self.flag_stationarity == True: \n",
    "            self.df = self.df_raw               # if no transoformation needed - just use df_raw\n",
    "            print('No need in transforms as stationarity is {}'.format(self.flag_stationarity)) ##\n",
    "        else: \n",
    "            # (1) start the iterative procedure of differencing\n",
    "            for i in range(1,self.max_order_diff + 1):\n",
    "                diff_helped = differencing(df,order=i)\n",
    "                if diff_helped == True:\n",
    "                    #print(self.df)\n",
    "                    self.flag_stationarity = diff_helped \n",
    "                    break \n",
    "            # (2) if differencing did not help do detrending \n",
    "            \n",
    "            #self.flag_stationarity  = False                    ##Delete, just for testing ##\n",
    "            \n",
    "            if self.flag_stationarity == False: \n",
    "                for i in range(1,self.max_order_detrend + 1):\n",
    "                    detrend_helped = detrending(df,order=i)\n",
    "                    if detrend_helped == True:\n",
    "                        #print(self.df)\n",
    "                        self.flag_stationarity = detrend_helped \n",
    "                        break\n",
    "        # write smth for the case when nothing helped, already written a logger warning in fit though\n",
    "       \n",
    "    def diagnostics(self,level='5%',**kwargs):\n",
    "        \"\"\" Possible diagnostics: \n",
    "                1. serial/autocorrelation of the residuals check via Ljung_Box test\n",
    "                2. residual acf plot \n",
    "            \n",
    "            @level = what confidence level to use in test Ljung_Box. \n",
    "                     NOTE: when test_assump called from fit method level is set by kwarg or default is 5%\n",
    "       \n",
    "            Possible kwargs to be added later:\n",
    "                @do_plot = boolean, show the acf plot of the residuals, default = False\n",
    "        \"\"\"\n",
    "        residuals = self.result.resid      \n",
    "        do_plot = kwargs.get('do_plot',False)\n",
    "        self.lag = 2                                       ##### THIS VARAIBLE NEEDS TO BE CREATED !!!\n",
    "        \n",
    "        def _ljbox_test():\n",
    "            \"\"\"H_0: the data are independently distributed, not enough evidence to supoprt serial corr\n",
    "            Returns: dataframe of summary of the test \n",
    "            \"\"\"\n",
    "            summary_ljb = pd.DataFrame(columns=['ljbvalue','p-value'])\n",
    "            for name in self.df.columns:\n",
    "                series = residuals[name]\n",
    "                result = acorr_ljungbox(series,lags=self.lag)\n",
    "                dic = {'ljbvalue':result[0][self.lag-1],'p-value':result[1][self.lag-1]}\n",
    "                summary_ljb = summary_ljb.append(dic,ignore_index=True)\n",
    "            self.summary_ljb = summary_ljb.set_index(self.df.columns) \n",
    "            \n",
    "            lvl = float(self.level[:-1])/100\n",
    "            res_white_flag = True                # if test failed, we assume we need to take action \n",
    "            for i in self.df.columns:\n",
    "                not_white = lvl > self.summary_ljb.loc[i,'p-value']\n",
    "                if (not_white == True):\n",
    "                    res_white_flag = False \n",
    "\n",
    "            return res_white_flag\n",
    "        \n",
    "        def _plot_res_acf(do_plot): \n",
    "            if do_plot:\n",
    "                for name in self.df.columns:\n",
    "                    series = residuals[name]\n",
    "                    print(\"Residuals autocorelation plot for {}\".format(name))\n",
    "                    plot_acf(series, lags=self.lag)\n",
    "                    pyplot.show()\n",
    "                    \n",
    "                return # _plot_res_act \n",
    "        \n",
    "        res_check = _ljbox_test()\n",
    "        _plot_res_acf(do_plot)           \n",
    "        \n",
    "        return res_check # for diag \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cl():\n",
    "    def granger(self,ts_1,ts_2,level,lag):\n",
    "        \"\"\"The Null hypothesis for grangercausalitytests is that the time series in the second column,\n",
    "            x2, does NOT Granger cause the time series in the first column, x1.\n",
    "            \n",
    "            @ts_1 - time series which is assumed to not granger cause ts_2 (regressor)\n",
    "            @ts_2 - time series which is assumed to be not granger cause ts_1 \n",
    "            @level - confidence level of ssr f test \n",
    "            @lag - lag at which we want the test\n",
    "        \"\"\"\n",
    "        array = self.df.iloc[:,[ts_2-1,ts_1-1]].values\n",
    "        \n",
    "        #Granger causality table for the last call of self.granger()\n",
    "        table = grangercausalitytests(array,maxlag=lag,verbose=False)[lag][0]\n",
    "        self.granger_table = pd.DataFrame.from_dict(table,orient='index')\n",
    "        old_names = list(self.granger_table.columns)\n",
    "        new_names = ['F-val', 'p-val', 'df_denom', 'df_num']\n",
    "        self.granger_table.rename(columns=dict(zip(old_names, new_names)), inplace=True)\n",
    "        \n",
    "        result = grangercausalitytests(array,maxlag=lag,verbose=False)[lag][0]['ssr_ftest']\n",
    "        \n",
    "        granger_flag = result[1] < float(level[:-1])/100          \n",
    "       \n",
    "        \n",
    "        return granger_flag # for granger \n",
    "\n",
    "    def plot(self, plot_type=None, lag = 1):\n",
    "\n",
    "        def lag_scatter():\n",
    "         \n",
    "            for name in self.df.columns:\n",
    "                series = self.df[name]\n",
    "                print(\"Lag plot where y is {}\".format(name))\n",
    "                lag_plot(series,lag)\n",
    "                pyplot.show()    \n",
    "\n",
    "            return ##\n",
    "        \n",
    "        def line_plot():\n",
    "       \n",
    "            for name in self.df.columns:\n",
    "                series = self.df[name]\n",
    "                series.plot(legend=True)\n",
    "                pyplot.show()\n",
    "            return ##\n",
    "    \n",
    "        def autocorrelation_plot():\n",
    "            for name in self.df.columns:\n",
    "                series = self.df[name]\n",
    "                print(\"Autocorelation plot for {}\".format(name)) \n",
    "                plot_acf(series, lags=lag)\n",
    "                pyplot.show()\n",
    "            \n",
    "        if plot_type == None:\n",
    "            lag_scatter() \n",
    "            line_plot()\n",
    "            autocorrelation_plot()\n",
    "        if (plot_type == ('line')):\n",
    "            line_plot()\n",
    "        if (plot_type == ('lag')):\n",
    "            lag_scatter()\n",
    "        if (plot_type == ('autocorrelation')):\n",
    "            autocorrelation_plot()\n",
    "        \n",
    "        return ## \n",
    "    \n",
    "    def interpretation(self, **kwargs):\n",
    "        \"\"\"\n",
    "        This method should have the functionality to interpret the status of the model after being trained and also document the various design choices\\\n",
    "        (i.e. parameters settings, assumptions, model selection, test method, dataset used). For example it can return a report-like looking formatted string.\\n\n",
    "        Please consider the following as possible model state interpretation:\\n\n",
    "           * For classification tasks depending on the underlying model: coeficient/feature weights, feature selection (random forest)\\n\n",
    "           * For clustering tasks: clusterings members/structure, distributions\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    \n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inca362",
   "language": "python",
   "name": "inca362"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
